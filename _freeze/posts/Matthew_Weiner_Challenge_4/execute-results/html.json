{
  "hash": "0d13acf9681ac4e358de2ae896102733",
  "result": {
    "markdown": "---\ntitle: \"Challenge 4\"\nauthor: \"Matthew Weiner\"\ndescription: \"More data wrangling: pivoting\"\ndate: \"03/29/2023\"\nformat:\n  html:\n    toc: true\n    code-fold: true\n    code-copy: true\n    code-tools: true\ncategories:\n  - challenge_4\n  - abc_poll\n\n---\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n\nknitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)\n```\n:::\n\n\n## Challenge Overview\n\nToday's challenge is to:\n\n1)  read in a data set, and describe the data set using both words and any supporting information (e.g., tables, etc)\n2)  tidy data (as needed, including sanity checks)\n3)  identify variables that need to be mutated\n4)  mutate variables and sanity check all mutations\n\n## Read in data\n\nRead in one (or more) of the following datasets, using the correct R package and command.\n\n-   abc_poll.csv ⭐\n-   poultry_tidy.xlsx or organiceggpoultry.xls⭐⭐\n-   FedFundsRate.csv⭐⭐⭐\n-   hotel_bookings.csv⭐⭐⭐⭐\n-   debt_in_trillions.xlsx ⭐⭐⭐⭐⭐\n\n\n## Introduction\n\nFor this challenge I chose to investigate the abc_poll dataset\n\n## Understanding the Data\n\nThe first thing I needed to do was to get a better understanding of what this dataset looked like and try to figure out what it was about. I was able to do this in the following code block which examines the shape of the datset as well as the names of the variables.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(readr)\nabc <- read_csv(\"_data/abc_poll_2021.csv\")\n\n# num of rows of dataset\nnrow(abc)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 527\n```\n:::\n\n```{.r .cell-code}\n#num of cols of dataset\nncol(abc)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 31\n```\n:::\n\n```{.r .cell-code}\n#name of all the columns\ncolnames(abc)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"id\"              \"xspanish\"        \"complete_status\" \"ppage\"          \n [5] \"ppeduc5\"         \"ppeducat\"        \"ppgender\"        \"ppethm\"         \n [9] \"pphhsize\"        \"ppinc7\"          \"ppmarit5\"        \"ppmsacat\"       \n[13] \"ppreg4\"          \"pprent\"          \"ppstaten\"        \"PPWORKA\"        \n[17] \"ppemploy\"        \"Q1_a\"            \"Q1_b\"            \"Q1_c\"           \n[21] \"Q1_d\"            \"Q1_e\"            \"Q1_f\"            \"Q2\"             \n[25] \"Q3\"              \"Q4\"              \"Q5\"              \"QPID\"           \n[29] \"ABCAGE\"          \"Contact\"         \"weights_pid\"    \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nnum_states <- n_distinct(abc$ppstaten)\nprint(num_states)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 49\n```\n:::\n:::\n\n\nThese initial investigations have led me to believe that this dataset represents the data collected about participants in some poll, likely political, as part of the news network ABC. Additionally, we can see that this is a nation-wide poll as almost every state is included in the dataset\n\nThe variables include personal information about the participants such as their education, their household size, their age, etc. There are also variables related to the questions asked to the partipants:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nabc_Q <- abc %>% select(starts_with(\"Q\"))%>% colnames(.)\nprint(abc_Q)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"Q1_a\" \"Q1_b\" \"Q1_c\" \"Q1_d\" \"Q1_e\" \"Q1_f\" \"Q2\"   \"Q3\"   \"Q4\"   \"Q5\"  \n[11] \"QPID\"\n```\n:::\n:::\n\n\n## Tidy Data \n\nWhen tidying up this data, we first want to check if there are any missing entries in the dataset.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#count number of missing entries \nsum(is.na(abc))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0\n```\n:::\n:::\n\nThe above codeblock shows us that there is no missing data in the typical form.\n\nHowever if we look at the results of the different questions asked to the participants we can see that there is a value called `Skipped`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntable(abc$Q1_a)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n   Approve Disapprove    Skipped \n       329        193          5 \n```\n:::\n:::\n\n\nIn order to clean this data up, we want to instead replace all `Skipped` questions with `NA` instead as this will make any future actions on this dataset easier.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nabc <- abc %>% mutate(across(starts_with(\"Q\"), ~ifelse(.==\"Skipped\", NA, .)))\n```\n:::\n\n\nThis codeblock will change every value that is `Skipped` to be `NA` instead. We can then view the results as part of our sanity check:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntable(abc$Q1_a)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n   Approve Disapprove \n       329        193 \n```\n:::\n:::\n\nWe can also confirm that this worked by checking the number of missing entries again:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsum(is.na(abc))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 86\n```\n:::\n:::\n\n\nAnother thing we could fix with this dataset is the format for some of the variables. For instance, the values of the variable `QPID` are:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nunique(abc$QPID)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"A Democrat\"     \"An Independent\" \"Something else\" \"A Republican\"  \n[5] NA              \n```\n:::\n:::\n\n\nWhile this is not a big deal, the articles at the start of each variable name are unnecessary and so we can mutate the dataset in order to remove those:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nabc <- abc %>%\n  mutate(QPID = gsub(\"^A\\\\s|^An\\\\s\", \"\", QPID))\n```\n:::\n\n\nNow we can perform a sanity check on this dataset to make sure that the articles were removed properly:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntable(abc$QPID)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n      Democrat    Independent     Republican Something else \n           176            168            152             28 \n```\n:::\n:::\n\n\n# Conclusion\n\nIn this challenge we saw how we were able to use R commands in order to mutate our dataset to improve readability and performance.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}